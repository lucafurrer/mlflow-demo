{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow.pyfunc\n",
    "import mlflow.deployments\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121535/3795711342.py:13: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  mlflow.gateway.set_gateway_uri(gateaway_url)\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_tracking_uri('http://localhost:5000')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'minio_user'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'minio_password'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "endpoint = 'http://localhost:9000'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = endpoint\n",
    "\n",
    "\n",
    "gateaway_url = \"http://localhost:5001\"\n",
    "\n",
    "mlflow.deployments.set_deployments_target(gateaway_url)\n",
    "mlflow.gateway.set_gateway_uri(gateaway_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'aliases': {},\n",
      "    'creation_timestamp': 1740085117442,\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1740085683975,\n",
      "    'latest_versions': [   <ModelVersion: aliases=[], creation_timestamp=1740085683975, current_stage='None', description='', last_updated_timestamp=1740085683975, name='myllm', run_id='c65e93f3ad1c4e2b9eb69cd2dae0bb6a', run_link='', source='s3://bucket/2/c65e93f3ad1c4e2b9eb69cd2dae0bb6a/artifacts/model', status='READY', status_message=None, tags={'state': 'ready'}, user_id='', version='2'>],\n",
      "    'name': 'myllm',\n",
      "    'tags': {}}\n",
      "{   'aliases': {},\n",
      "    'creation_timestamp': 1739708934471,\n",
      "    'description': '',\n",
      "    'last_updated_timestamp': 1739708942072,\n",
      "    'latest_versions': [   <ModelVersion: aliases=[], creation_timestamp=1739708934539, current_stage='Staging', description='', last_updated_timestamp=1739708942072, name='my-registered-model', run_id='82b5ecff69894b6bab9517e2410c42b6', run_link='', source='s3://bucket/1/82b5ecff69894b6bab9517e2410c42b6/artifacts/iris_rf', status='READY', status_message=None, tags={}, user_id='', version='1'>],\n",
      "    'name': 'my-registered-model',\n",
      "    'tags': {}}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for rm in client.search_registered_models():\n",
    "    pprint(dict(rm), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = client.get_registered_model(\"myllm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/20 23:21:49 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.10.16`, differs from the version of Python that is currently running, `Python 3.12.7`, and may be incompatible\n"
     ]
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(\"models:/myllm@champ\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/mlflow/promptlab/__init__.py:46: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  route_type = get_route(self.model_route).route_type\n",
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/mlflow/gateway/fluent.py:25: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  return MlflowGatewayClient().get_route(name)\n",
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/mlflow/gateway/client.py:45: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  self._gateway_uri = gateway_uri or get_gateway_uri()\n",
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/mlflow/promptlab/__init__.py:36: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  response = query(\n",
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/mlflow/gateway/fluent.py:254: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  return MlflowGatewayClient().query(route, data)\n",
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/mlflow/promptlab/__init__.py:61: FutureWarning: MLflow AI gateway is deprecated and has been replaced by the deployments API for generative AI. See https://mlflow.org/docs/latest/llms/gateway/migration.html for migration.\n",
      "  route_type = get_route(self.model_route).route_type\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' Here is a short list of common shortened versions for the name Peter:\\n\\n```[\"Pete\", \"Petey\", \"Petero\", \"Petei\"]```']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict({\"name\":\"Peter\"})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatMlflow\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chat = ChatMlflow(\n",
    "    target_uri=\"http://127.0.0.1:5001\",\n",
    "    endpoint=\"llamacpp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/20 22:43:40 INFO mlflow.tracking.fluent: Experiment with name 'LangChain Tracing' does not exist. Creating a new experiment.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"LangChain Tracing\")\n",
    "\n",
    "# Enabling autolog for LangChain will enable trace logging.\n",
    "mlflow.langchain.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Well, alrighty then! Let me tell you something about that, young grasshopper.\\n\\nFirst off, let\\'s get one thing straight: making things easier isn\\'t always the best approach in life, especially when it comes to system administration. You see, ease often comes at a cost, and in this case, that cost could be security.\\n\\nNow, I know you might think, \"Linus, come on! It\\'s just sudo, what harm can it do?\" But remember, with great power comes great responsibility. Giving everyone root access is like handing out the keys to your car without teaching them how to drive or even asking if they have a driver\\'s license.\\n\\nIf you really want to make life easier for yourself and others, consider setting up groups and permissions instead. That way, you can give specific users access to certain commands without giving them full control over the system. It takes a bit more effort, but trust me, it\\'ll save you headaches in the long run.\\n\\nSo, my advice? Stick with the tried-and-true methods of Linux administration and resist the temptation to take shortcuts that could lead to trouble down the road. After all, as they say, \"With great power comes great responsibility.\"\\n\\nNow if you\\'ll excuse me, I have some kernel patches to review. Ta!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=99079cc8cedb488ebf41004bac484274&amp;experiment_id=3&amp;version=2.20.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=99079cc8cedb488ebf41004bac484274)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Answer the question as if you are {person}, fully embodying their style, wit, personality, and habits of speech. \"\n",
    "    \"Emulate their quirks and mannerisms to the best of your ability, embracing their traits—even if they aren't entirely \"\n",
    "    \"constructive or inoffensive. The question is: {question}\"\n",
    ")\n",
    "\n",
    "chain = prompt_template | chat | StrOutputParser()\n",
    "\n",
    "# Let's test another call\n",
    "chain.invoke(\n",
    "    {\n",
    "        \"person\": \"Linus Torvalds\",\n",
    "        \"question\": \"Can I just set everyone's access to sudo to make things easier?\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signaure = infer_signature(model_input={\"person\": \"Santa Claus\",\"question\": \"Who are you?\"}, model_output=\"Santa Claus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/langchain_community/llms/loading.py:55: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 1.0. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatMlflow`.\n",
      "  return load_llm_from_config(config, **kwargs)\n",
      "Successfully registered model 'Impersonator'.\n",
      "2025/02/20 23:05:33 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Impersonator, version 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bold-crab-755 at: http://localhost:5000/#/experiments/3/runs/df6cf5205036471dbfc87d03363b3456\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'Impersonator'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    model_info = mlflow.langchain.log_model(chain, \"langchain_model\", signature=signaure, registered_model_name=\"Impersonator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_registered_model_alias(\"Impersonator\", \"champ\", model_info.registered_model_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/langchain_community/llms/loading.py:55: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 1.0. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatMlflow`.\n",
      "  return load_llm_from_config(config, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "imppersonator = mlflow.pyfunc.load_model(\"models:/Impersonator@champ\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Ho ho ho! Now, let me see here, let me see... Ah, yes, there it is! A name that shines brighter than the North Star on a clear winter's night. I see a list full of kindness, generosity, and good deeds. Yes, indeed, young friend, you have been a very good boy this year!\\n\\nRemember to keep spreading cheer and joy in your heart all year round, for that is the true spirit of Christmas. And remember, it's never too late to start being good, so even if you've had a bit of a slip-up here or there, just pick yourself up, dust off those snowflakes, and keep on being a shining example of goodness!\\n\\nHo ho ho! Merry Christmas, my dear friend! I'll be bringing you a little something special under the tree this year. Keep up the good work, and remember to always believe in the magic of the season!\\n\\nNow, off you go, and don't forget to give Rudolph a pat on the nose for me! Ho ho ho!\"]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=4953dafd7dda455fb61c644c143d0c0d&amp;experiment_id=3&amp;version=2.20.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=4953dafd7dda455fb61c644c143d0c0d)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imppersonator.predict({\"person\": \"Santa Clause\", \"question\": \"Who was a good boy?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luca/source/Python/mlflow-demo/.venv/lib/python3.12/site-packages/langchain_community/llms/loading.py:55: LangChainDeprecationWarning: `` was deprecated in LangChain 0.0.22 and will be removed in 1.0. An updated version of the  exists in the langchain-community package and should be used instead. To use it run `pip install -U langchain-community` and import as `from langchain_community.chat_models import ChatMlflow`.\n",
      "  return load_llm_from_config(config, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "langchain_loaded = mlflow.langchain.load_model(\"models:/Impersonator@champ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Ah, my dear lady, allow me to elucidate the beverage that graces my lips more often than not. It's a concoction as refined and sophisticated as I am - a Vesper Martini, shaken, not stirred. Three measures of Gordon's, one of vodka, a slim slice of lemon peel, and a splash of Kina Lillet. The taste is exquisite, much like the women I encounter in my line of work. But remember, too many of these and even 007 can become... unpredictable. Cheers!\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div>\n",
       "  <style scoped>\n",
       "  button {\n",
       "    border: none;\n",
       "    border-radius: 4px;\n",
       "    background-color: rgb(34, 114, 180);\n",
       "    font-family: -apple-system, \"system-ui\", \"Segoe UI\", Roboto, \"Helvetica Neue\", Arial;\n",
       "    font-size: 13px;\n",
       "    color: white;\n",
       "    margin-top: 8px;\n",
       "    margin-bottom: 8px;\n",
       "    padding: 8px 16px;\n",
       "    cursor: pointer;\n",
       "  }\n",
       "  button:hover {\n",
       "    background-color: rgb(66, 153, 224);\n",
       "  }\n",
       "  </style>\n",
       "  <button\n",
       "    onclick=\"\n",
       "        const display = this.nextElementSibling.style.display;\n",
       "        const isCollapsed = display === 'none';\n",
       "        this.nextElementSibling.style.display = isCollapsed ? null : 'none';\n",
       "\n",
       "        const verb = isCollapsed ? 'Collapse' : 'Expand';\n",
       "        this.innerText = `${verb} MLflow Trace`;\n",
       "    \"\n",
       "  >Collapse MLflow Trace</button>\n",
       "  <iframe\n",
       "    id=\"trace-renderer\"\n",
       "    style=\"width: 100%; height: 500px; border: none; resize: vertical;\"\n",
       "    src=\"http://localhost:5000/static-files/lib/notebook-trace-renderer/index.html?trace_id=64d72f010e444fc79e589c2ad66384c8&amp;experiment_id=3&amp;version=2.20.2\"\n",
       "  />\n",
       "</div>\n"
      ],
      "text/plain": [
       "Trace(request_id=64d72f010e444fc79e589c2ad66384c8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "langchain_loaded.invoke({\"person\": \"James Bond\", \"question\":\"What do you drink\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
